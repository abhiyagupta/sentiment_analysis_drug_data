{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# running in colab before moving to gitpod"
      ],
      "metadata": {
        "id": "Ezme2LXIxV-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8A7qIhz0iiD_",
        "outputId": "786e3e16-d78e-49d9-ba0f-64208920bfa4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
            "Collecting mlflow>=1.20.0 (from -r requirements.txt (line 5))\n",
            "  Downloading mlflow-3.3.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: transformers>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.55.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.8.0+cu126)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: lightgbm>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.6.0)\n",
            "Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6->-r requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6->-r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting mlflow-skinny==3.3.2 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading mlflow_skinny-3.3.2-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.3.2 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading mlflow_tracing-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow>=1.20.0->-r requirements.txt (line 5)) (3.1.2)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=1.20.0->-r requirements.txt (line 5)) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=1.20.0->-r requirements.txt (line 5)) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow>=1.20.0->-r requirements.txt (line 5)) (2.0.43)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading databricks_sdk-0.64.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.36.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (0.34.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=1.20.0->-r requirements.txt (line 5))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.20.0->-r requirements.txt (line 6)) (1.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.47.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.57b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow>=1.20.0->-r requirements.txt (line 5)) (0.6.1)\n",
            "Downloading mlflow-3.3.2-py3-none-any.whl (26.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.3.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.3.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.64.0-py3-none-any.whl (703 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.4/703.4 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.16.5 databricks-sdk-0.64.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.3.2 mlflow-skinny-3.3.2 mlflow-tracing-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')   #  new dependency in recent NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RneJpCpPy5-h",
        "outputId": "b2002bb5-b6c2-4312-b865-f113c6e20281"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing train"
      ],
      "metadata": {
        "id": "KDd_o8dd6hg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyXwUDtlzPo2",
        "outputId": "5aecadaa-d148-4b88-ea9b-6a3d209e4262"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "\n",
            "=== LightGBM ===\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "2025/09/01 05:56:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/01 05:56:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "📊 Macro F1: 0.4772 (±0.0238)\n",
            "📈 Individual scores: ['0.513', '0.448', '0.458', '0.495', '0.472']\n",
            "✅ Meets target (0.470)\n",
            "\n",
            "=== XGBoost ===\n",
            "XGBoost CV: 100% 5/5 [08:47<00:00, 105.41s/it]\n",
            "2025/09/01 06:07:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/01 06:07:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "📊 Macro F1: 0.4138 (±0.0284)\n",
            "📈 Individual scores: ['0.454', '0.365', '0.414', '0.418', '0.418']\n",
            "⚠️  Below target (0.470)\n",
            "\n",
            "=== Random Forest ===\n",
            "2025/09/01 06:08:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/01 06:08:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "📊 Macro F1: 0.3229 (±0.0115)\n",
            "📈 Individual scores: ['0.334', '0.314', '0.316', '0.312', '0.339']\n",
            "⚠️  Below target (0.470)\n",
            "\n",
            "🏆 BEST MODEL: LightGBM\n",
            "   Macro F1: 0.4772\n",
            "\n",
            "💾 Model pipeline saved to: best_model.pkl\n",
            "   This includes:\n",
            "   ✓ Trained model\n",
            "   ✓ TF-IDF vectorizer\n",
            "   ✓ Label encoder\n",
            "   ✓ Preprocessing parameters\n",
            "\n",
            "📊 Creating performance visualizations...\n",
            "   Saved as: model_comparison.png\n",
            "\n",
            "============================================================\n",
            "TRAINING SUMMARY\n",
            "============================================================\n",
            "LightGBM      | F1: 0.4772 (±0.0238) | ✅ PASS\n",
            "XGBoost       | F1: 0.4138 (±0.0284) | ❌ FAIL\n",
            "Random Forest | F1: 0.3229 (±0.0115) | ❌ FAIL\n",
            "\n",
            "🎯 Target F1-score: 0.47\n",
            "🏆 Best achieved: 0.4772 (LightGBM)\n",
            "🎉 SUCCESS! Ready for submission.\n",
            "\n",
            "📁 Files created:\n",
            "   • best_model.pkl (trained pipeline)\n",
            "   • model_comparison.png (performance chart)\n",
            "   • MLflow logs in ./mlruns/\n",
            "\n",
            "▶️  Next step: Use model.py to make predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test single prediction"
      ],
      "metadata": {
        "id": "uplLjMMu6oLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/model.py --predict \"This drug works great\" --drug \"Aspirin\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA1L9Qm-zJUQ",
        "outputId": "1ad3522a-1672-437f-cd63-9bfe8da643eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:16:04.828296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707364.848607   10529 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707364.854813   10529 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707364.871062   10529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707364.871090   10529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707364.871094   10529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707364.871099   10529 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:16:04.875865: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Loaded traditional model: LGBMClassifier\n",
            "Label classes: [np.int64(0), np.int64(1), np.int64(2)]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "Input: This drug works great\n",
            "Drug: Aspirin\n",
            "Predicted Sentiment: 0\n",
            "Sentiment label: Positive\n",
            "Probabilities: [0.75176083 0.14372534 0.10451383]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/model.py --predict \"This medication caused severe side effects\" --drug \"DrugX\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU22A7n46wRn",
        "outputId": "d30a7a37-f0f6-4abc-f51a-fe739d0df933"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:16:28.140019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707388.159864   10672 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707388.165897   10672 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707388.181004   10672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707388.181028   10672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707388.181034   10672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707388.181037   10672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:16:28.185577: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Loaded traditional model: LGBMClassifier\n",
            "Label classes: [np.int64(0), np.int64(1), np.int64(2)]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "Input: This medication caused severe side effects\n",
            "Drug: DrugX\n",
            "Predicted Sentiment: 1\n",
            "Sentiment label: Negative\n",
            "Probabilities: [0.1589019  0.69005004 0.15104805]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing transformer"
      ],
      "metadata": {
        "id": "yqbeAefO6-ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train_transformer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3K5-eP06__V",
        "outputId": "463efb3d-57b3-4d6f-8917-aef3ae40dcfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:17:37.011479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707457.031069   10959 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707457.037043   10959 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707457.052167   10959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707457.052197   10959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707457.052201   10959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707457.052207   10959 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:17:37.056792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "2025/09/01 06:17:41 INFO mlflow.tracking.fluent: Experiment with name 'Drug_Sentiment_Analysis_Transformer' does not exist. Creating a new experiment.\n",
            "🔄 Loading and preprocessing data...\n",
            "\n",
            "📊 Initial data statistics:\n",
            "  total_rows: 5279\n",
            "  sentiment_distribution: {2: 3825, 1: 837, 0: 617}\n",
            "  avg_text_length: 2075.7010797499524\n",
            "  empty_text_count: 0\n",
            "  missing_sentiment: 0\n",
            "  unique_drugs: 102\n",
            "  most_common_drugs: {'ocrevus': 676, 'gilenya': 666, 'ocrelizumab': 441, 'entyvio': 303, 'humira': 270}\n",
            "Sentiment distribution after cleaning:\n",
            "sentiment\n",
            "neutral     3825\n",
            "negative     837\n",
            "positive     617\n",
            "Name: count, dtype: int64\n",
            "\n",
            "📊 Final data statistics:\n",
            "  total_rows: 5279\n",
            "  sentiment_distribution: {'neutral': 3825, 'negative': 837, 'positive': 617}\n",
            "  avg_text_length: 2075.7010797499524\n",
            "  empty_text_count: 0\n",
            "  missing_sentiment: 0\n",
            "  unique_drugs: 102\n",
            "  most_common_drugs: {'ocrevus': 676, 'gilenya': 666, 'ocrelizumab': 441, 'entyvio': 303, 'humira': 270}\n",
            "\n",
            "🏷️  Found sentiment classes: ['negative', 'neutral', 'positive']\n",
            "✅ Label distribution: {0: 617, 1: 837, 2: 3825}\n",
            "\n",
            "🔪 Splitting data...\n",
            "📊 Train set: 4223 samples\n",
            "📊 Val set: 1056 samples\n",
            "📊 Train label dist: {0: 494, 1: 669, 2: 3060}\n",
            "📊 Val label dist: {0: 123, 1: 168, 2: 765}\n",
            "\n",
            "🤖 Loading model: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
            "config.json: 100% 929/929 [00:00<00:00, 5.19MB/s]\n",
            "vocab.json: 899kB [00:00, 16.6MB/s]\n",
            "merges.txt: 456kB [00:00, 75.0MB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 2.13MB/s]\n",
            "🔤 Tokenizing datasets...\n",
            "Map: 100% 4223/4223 [00:03<00:00, 1347.99 examples/s]\n",
            "Map: 100% 1056/1056 [00:00<00:00, 1690.00 examples/s]\n",
            "pytorch_model.bin: 100% 501M/501M [00:06<00:00, 76.6MB/s]\n",
            "model.safetensors:   0% 0.00/501M [00:00<?, ?B/s]Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/content/src/train_transformer.py:229: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\n",
            "🚀 Starting training...\n",
            "model.safetensors:  13% 67.0M/501M [00:02<00:18, 23.3MB/s]\n",
            "model.safetensors:  73% 367M/501M [00:05<00:01, 97.7MB/s]\n",
            "  0% 1/528 [00:03<35:06,  4.00s/it]\u001b[A\n",
            "  0% 2/528 [00:04<15:29,  1.77s/it]\u001b[A\n",
            "  1% 3/528 [00:04<09:07,  1.04s/it]\u001b[A\n",
            "model.safetensors: 100% 501M/501M [00:07<00:00, 64.7MB/s]\n",
            "\n",
            "  1% 5/528 [00:04<04:34,  1.90it/s]\u001b[A\n",
            "  1% 6/528 [00:04<03:35,  2.42it/s]\u001b[A\n",
            "  1% 7/528 [00:05<02:57,  2.93it/s]\u001b[A\n",
            "  2% 8/528 [00:05<02:33,  3.39it/s]\u001b[A\n",
            "  2% 9/528 [00:05<02:16,  3.80it/s]\u001b[A\n",
            "  2% 10/528 [00:05<02:05,  4.13it/s]\u001b[A\n",
            "  2% 11/528 [00:05<01:57,  4.38it/s]\u001b[A\n",
            "  2% 12/528 [00:06<01:52,  4.59it/s]\u001b[A\n",
            "  2% 13/528 [00:06<01:48,  4.75it/s]\u001b[A\n",
            "  3% 14/528 [00:06<01:46,  4.84it/s]\u001b[A\n",
            "  3% 15/528 [00:06<01:44,  4.91it/s]\u001b[A\n",
            "  3% 16/528 [00:06<01:42,  4.97it/s]\u001b[A\n",
            "  3% 17/528 [00:07<01:42,  5.00it/s]\u001b[A\n",
            "  3% 18/528 [00:07<01:41,  5.04it/s]\u001b[A\n",
            "  4% 19/528 [00:07<01:40,  5.06it/s]\u001b[A\n",
            "  4% 20/528 [00:07<01:40,  5.08it/s]\u001b[A\n",
            "  4% 21/528 [00:07<01:40,  5.06it/s]\u001b[A\n",
            "  4% 22/528 [00:08<01:39,  5.10it/s]\u001b[A\n",
            "  4% 23/528 [00:08<01:39,  5.10it/s]\u001b[A\n",
            "  5% 24/528 [00:08<01:38,  5.11it/s]\u001b[A\n",
            "  5% 25/528 [00:08<01:38,  5.11it/s]\u001b[A\n",
            "  5% 26/528 [00:08<01:38,  5.10it/s]\u001b[A\n",
            "  5% 27/528 [00:09<01:38,  5.11it/s]\u001b[A\n",
            "  5% 28/528 [00:09<01:37,  5.11it/s]\u001b[A\n",
            "  5% 29/528 [00:09<01:37,  5.11it/s]\u001b[A\n",
            "  6% 30/528 [00:09<01:37,  5.11it/s]\u001b[A\n",
            "  6% 31/528 [00:09<01:37,  5.07it/s]\u001b[A\n",
            "  6% 32/528 [00:10<01:37,  5.09it/s]\u001b[A\n",
            "  6% 33/528 [00:10<01:37,  5.09it/s]\u001b[A\n",
            "  6% 34/528 [00:10<01:37,  5.05it/s]\u001b[A\n",
            "  7% 35/528 [00:10<01:37,  5.04it/s]\u001b[A\n",
            "  7% 36/528 [00:10<01:37,  5.03it/s]\u001b[A\n",
            "  7% 37/528 [00:11<01:37,  5.03it/s]\u001b[A\n",
            "  7% 38/528 [00:11<01:37,  5.03it/s]\u001b[A\n",
            "  7% 39/528 [00:11<01:37,  5.02it/s]\u001b[A\n",
            "  8% 40/528 [00:11<01:37,  5.00it/s]\u001b[A\n",
            "  8% 41/528 [00:11<01:38,  4.94it/s]\u001b[A\n",
            "  8% 42/528 [00:12<01:38,  4.92it/s]\u001b[A\n",
            "  8% 43/528 [00:12<01:38,  4.94it/s]\u001b[A\n",
            "  8% 44/528 [00:12<01:37,  4.96it/s]\u001b[A\n",
            "  9% 45/528 [00:12<01:36,  4.99it/s]\u001b[A\n",
            "  9% 46/528 [00:12<01:36,  5.00it/s]\u001b[A\n",
            "  9% 47/528 [00:13<01:35,  5.03it/s]\u001b[A\n",
            "  9% 48/528 [00:13<01:34,  5.07it/s]\u001b[A\n",
            "  9% 49/528 [00:13<01:34,  5.08it/s]\u001b[A\n",
            "  9% 50/528 [00:13<01:33,  5.09it/s]\u001b[A\n",
            "\u001b[A{'loss': 1.0903, 'grad_norm': 1.7778308391571045, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.38}\n",
            "\n",
            "  9% 50/528 [00:13<01:33,  5.09it/s]\u001b[A\n",
            " 10% 51/528 [00:13<01:34,  5.04it/s]\u001b[A\n",
            " 10% 52/528 [00:14<01:33,  5.06it/s]\u001b[A\n",
            " 10% 53/528 [00:14<01:33,  5.06it/s]\u001b[A\n",
            " 10% 54/528 [00:14<01:33,  5.06it/s]\u001b[A\n",
            " 10% 55/528 [00:14<01:33,  5.05it/s]\u001b[A\n",
            " 11% 56/528 [00:14<01:35,  4.92it/s]\u001b[A\n",
            " 11% 57/528 [00:15<01:47,  4.38it/s]\u001b[A\n",
            " 11% 58/528 [00:15<01:53,  4.15it/s]\u001b[A\n",
            " 11% 59/528 [00:15<01:56,  4.02it/s]\u001b[A\n",
            " 11% 60/528 [00:15<01:52,  4.16it/s]\u001b[A\n",
            " 12% 61/528 [00:16<01:47,  4.35it/s]\u001b[A\n",
            " 12% 62/528 [00:16<01:45,  4.40it/s]\u001b[A\n",
            " 12% 63/528 [00:16<01:42,  4.54it/s]\u001b[A\n",
            " 12% 64/528 [00:16<01:40,  4.63it/s]\u001b[A\n",
            " 12% 65/528 [00:16<01:44,  4.44it/s]\u001b[A\n",
            " 12% 66/528 [00:17<02:05,  3.69it/s]\u001b[A\n",
            " 13% 67/528 [00:17<01:56,  3.96it/s]\u001b[A\n",
            " 13% 68/528 [00:17<01:50,  4.18it/s]\u001b[A\n",
            " 13% 69/528 [00:18<01:46,  4.30it/s]\u001b[A\n",
            " 13% 70/528 [00:18<01:44,  4.38it/s]\u001b[A\n",
            " 13% 71/528 [00:18<01:42,  4.47it/s]\u001b[A\n",
            " 14% 72/528 [00:18<01:53,  4.01it/s]\u001b[A\n",
            " 14% 73/528 [00:19<01:57,  3.88it/s]\u001b[A\n",
            " 14% 74/528 [00:19<01:57,  3.87it/s]\u001b[A\n",
            " 14% 75/528 [00:19<01:49,  4.12it/s]\u001b[A\n",
            " 14% 76/528 [00:19<01:44,  4.32it/s]\u001b[A\n",
            " 15% 77/528 [00:19<01:41,  4.46it/s]\u001b[A\n",
            " 15% 78/528 [00:20<01:38,  4.57it/s]\u001b[A\n",
            " 15% 79/528 [00:20<01:37,  4.59it/s]\u001b[A\n",
            " 15% 80/528 [00:20<01:36,  4.64it/s]\u001b[A\n",
            " 15% 81/528 [00:20<01:36,  4.61it/s]\u001b[A\n",
            " 16% 82/528 [00:21<01:43,  4.31it/s]\u001b[A\n",
            " 16% 83/528 [00:21<01:51,  4.01it/s]\u001b[A\n",
            " 16% 84/528 [00:21<01:57,  3.78it/s]\u001b[A\n",
            " 16% 85/528 [00:21<01:49,  4.06it/s]\u001b[A\n",
            " 16% 86/528 [00:22<01:44,  4.23it/s]\u001b[A\n",
            " 16% 87/528 [00:22<01:39,  4.44it/s]\u001b[A\n",
            " 17% 88/528 [00:22<01:38,  4.45it/s]\u001b[A\n",
            " 17% 89/528 [00:22<01:45,  4.17it/s]\u001b[A\n",
            " 17% 90/528 [00:22<01:44,  4.20it/s]\u001b[A\n",
            " 17% 91/528 [00:23<01:47,  4.06it/s]\u001b[A\n",
            " 17% 92/528 [00:23<01:58,  3.68it/s]\u001b[A\n",
            " 18% 93/528 [00:23<02:16,  3.19it/s]\u001b[A\n",
            " 18% 94/528 [00:24<02:45,  2.63it/s]\u001b[A\n",
            " 18% 95/528 [00:25<03:11,  2.26it/s]\u001b[A\n",
            " 18% 96/528 [00:25<02:56,  2.45it/s]\u001b[A\n",
            " 18% 97/528 [00:25<02:28,  2.90it/s]\u001b[A\n",
            " 19% 98/528 [00:25<02:11,  3.27it/s]\u001b[A\n",
            " 19% 99/528 [00:26<01:59,  3.60it/s]\u001b[A\n",
            " 19% 100/528 [00:26<01:52,  3.82it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.7598, 'grad_norm': 3.4264867305755615, 'learning_rate': 1.98e-05, 'epoch': 0.76}\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.6925938725471497, 'eval_f1_macro': 0.3430991271281652, 'eval_f1_micro': 0.7301136363636364, 'eval_f1_weighted': 0.639828411153275, 'eval_runtime': 1.7175, 'eval_samples_per_second': 614.846, 'eval_steps_per_second': 19.214, 'epoch': 0.76}\n",
            "100% 33/33 [00:01<00:00, 20.13it/s]\n",
            "\n",
            " 19% 101/528 [00:37<25:12,  3.54s/it]\u001b[A\n",
            " 19% 102/528 [00:37<18:13,  2.57s/it]\u001b[A\n",
            " 20% 103/528 [00:38<13:28,  1.90s/it]\u001b[A\n",
            " 20% 104/528 [00:38<09:59,  1.41s/it]\u001b[A\n",
            " 20% 105/528 [00:38<07:26,  1.06s/it]\u001b[A\n",
            " 20% 106/528 [00:38<05:37,  1.25it/s]\u001b[A\n",
            " 20% 107/528 [00:39<04:22,  1.60it/s]\u001b[A\n",
            " 20% 108/528 [00:39<03:31,  1.99it/s]\u001b[A\n",
            " 21% 109/528 [00:39<02:53,  2.42it/s]\u001b[A\n",
            " 21% 110/528 [00:39<02:27,  2.83it/s]\u001b[A\n",
            " 21% 111/528 [00:39<02:09,  3.21it/s]\u001b[A\n",
            " 21% 112/528 [00:40<01:56,  3.58it/s]\u001b[A\n",
            " 21% 113/528 [00:40<01:46,  3.89it/s]\u001b[A\n",
            " 22% 114/528 [00:40<01:39,  4.14it/s]\u001b[A\n",
            " 22% 115/528 [00:40<01:35,  4.32it/s]\u001b[A\n",
            " 22% 116/528 [00:40<01:32,  4.46it/s]\u001b[A\n",
            " 22% 117/528 [00:41<01:33,  4.40it/s]\u001b[A\n",
            " 22% 118/528 [00:41<01:48,  3.79it/s]\u001b[A\n",
            " 23% 119/528 [00:41<01:57,  3.47it/s]\u001b[A\n",
            " 23% 120/528 [00:42<02:00,  3.39it/s]\u001b[A\n",
            " 23% 121/528 [00:42<02:04,  3.27it/s]\u001b[A\n",
            " 23% 122/528 [00:42<02:09,  3.15it/s]\u001b[A\n",
            " 23% 123/528 [00:43<02:06,  3.20it/s]\u001b[A\n",
            " 23% 124/528 [00:43<02:04,  3.26it/s]\u001b[A\n",
            " 24% 125/528 [00:43<02:01,  3.31it/s]\u001b[A\n",
            " 24% 126/528 [00:43<01:54,  3.51it/s]\u001b[A\n",
            " 24% 127/528 [00:44<01:45,  3.81it/s]\u001b[A\n",
            " 24% 128/528 [00:44<01:38,  4.07it/s]\u001b[A\n",
            " 24% 129/528 [00:44<01:33,  4.29it/s]\u001b[A\n",
            " 25% 130/528 [00:44<01:30,  4.42it/s]\u001b[A\n",
            " 25% 131/528 [00:44<01:27,  4.53it/s]\u001b[A\n",
            " 25% 132/528 [00:45<01:24,  4.67it/s]\u001b[A\n",
            " 25% 133/528 [00:45<01:23,  4.73it/s]\u001b[A\n",
            " 25% 134/528 [00:45<01:22,  4.75it/s]\u001b[A\n",
            " 26% 135/528 [00:45<01:22,  4.75it/s]\u001b[A\n",
            " 26% 136/528 [00:46<01:22,  4.75it/s]\u001b[A\n",
            " 26% 137/528 [00:46<01:22,  4.76it/s]\u001b[A\n",
            " 26% 138/528 [00:46<01:21,  4.77it/s]\u001b[A\n",
            " 26% 139/528 [00:46<01:21,  4.78it/s]\u001b[A\n",
            " 27% 140/528 [00:46<01:21,  4.77it/s]\u001b[A\n",
            " 27% 141/528 [00:47<01:21,  4.75it/s]\u001b[A\n",
            " 27% 142/528 [00:47<01:22,  4.65it/s]\u001b[A\n",
            " 27% 143/528 [00:47<01:22,  4.69it/s]\u001b[A\n",
            " 27% 144/528 [00:47<01:21,  4.73it/s]\u001b[A\n",
            " 27% 145/528 [00:47<01:22,  4.62it/s]\u001b[A\n",
            " 28% 146/528 [00:48<01:21,  4.70it/s]\u001b[A\n",
            " 28% 147/528 [00:48<01:22,  4.62it/s]\u001b[A\n",
            " 28% 148/528 [00:48<01:32,  4.13it/s]\u001b[A\n",
            " 28% 149/528 [00:48<01:31,  4.15it/s]\u001b[A\n",
            " 28% 150/528 [00:49<01:35,  3.96it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.7465, 'grad_norm': 5.155370235443115, 'learning_rate': 1.7710280373831775e-05, 'epoch': 1.14}\n",
            "\n",
            " 28% 150/528 [00:49<01:35,  3.96it/s]\u001b[A\n",
            " 29% 151/528 [00:49<01:38,  3.83it/s]\u001b[A\n",
            " 29% 152/528 [00:49<01:35,  3.94it/s]\u001b[A\n",
            " 29% 153/528 [00:50<01:44,  3.58it/s]\u001b[A\n",
            " 29% 154/528 [00:50<01:48,  3.44it/s]\u001b[A\n",
            " 29% 155/528 [00:50<01:56,  3.19it/s]\u001b[A\n",
            " 30% 156/528 [00:51<01:52,  3.30it/s]\u001b[A\n",
            " 30% 157/528 [00:51<01:56,  3.18it/s]\u001b[A\n",
            " 30% 158/528 [00:51<01:57,  3.15it/s]\u001b[A\n",
            " 30% 159/528 [00:51<01:58,  3.11it/s]\u001b[A\n",
            " 30% 160/528 [00:52<02:05,  2.93it/s]\u001b[A\n",
            " 30% 161/528 [00:52<02:06,  2.91it/s]\u001b[A\n",
            " 31% 162/528 [00:53<02:04,  2.94it/s]\u001b[A\n",
            " 31% 163/528 [00:53<02:01,  3.00it/s]\u001b[A\n",
            " 31% 164/528 [00:53<01:57,  3.09it/s]\u001b[A\n",
            " 31% 165/528 [00:54<01:58,  3.07it/s]\u001b[A\n",
            " 31% 166/528 [00:54<02:03,  2.93it/s]\u001b[A\n",
            " 32% 167/528 [00:54<02:01,  2.98it/s]\u001b[A\n",
            " 32% 168/528 [00:55<01:55,  3.12it/s]\u001b[A\n",
            " 32% 169/528 [00:55<01:45,  3.41it/s]\u001b[A\n",
            " 32% 170/528 [00:55<01:34,  3.77it/s]\u001b[A\n",
            " 32% 171/528 [00:55<01:36,  3.70it/s]\u001b[A\n",
            " 33% 172/528 [00:55<01:35,  3.74it/s]\u001b[A\n",
            " 33% 173/528 [00:56<01:43,  3.43it/s]\u001b[A\n",
            " 33% 174/528 [00:56<01:35,  3.70it/s]\u001b[A\n",
            " 33% 175/528 [00:56<01:30,  3.92it/s]\u001b[A\n",
            " 33% 176/528 [00:56<01:24,  4.15it/s]\u001b[A\n",
            " 34% 177/528 [00:57<01:23,  4.23it/s]\u001b[A\n",
            " 34% 178/528 [00:57<01:22,  4.24it/s]\u001b[A\n",
            " 34% 179/528 [00:57<01:20,  4.34it/s]\u001b[A\n",
            " 34% 180/528 [00:57<01:18,  4.45it/s]\u001b[A\n",
            " 34% 181/528 [00:58<01:17,  4.46it/s]\u001b[A\n",
            " 34% 182/528 [00:58<01:15,  4.56it/s]\u001b[A\n",
            " 35% 183/528 [00:58<01:14,  4.62it/s]\u001b[A\n",
            " 35% 184/528 [00:58<01:13,  4.69it/s]\u001b[A\n",
            " 35% 185/528 [00:58<01:12,  4.72it/s]\u001b[A\n",
            " 35% 186/528 [00:59<01:12,  4.74it/s]\u001b[A\n",
            " 35% 187/528 [00:59<01:11,  4.76it/s]\u001b[A\n",
            " 36% 188/528 [00:59<01:11,  4.77it/s]\u001b[A\n",
            " 36% 189/528 [00:59<01:12,  4.68it/s]\u001b[A\n",
            " 36% 190/528 [00:59<01:11,  4.72it/s]\u001b[A\n",
            " 36% 191/528 [01:00<01:13,  4.59it/s]\u001b[A\n",
            " 36% 192/528 [01:00<01:12,  4.62it/s]\u001b[A\n",
            " 37% 193/528 [01:00<01:15,  4.41it/s]\u001b[A\n",
            " 37% 194/528 [01:00<01:16,  4.39it/s]\u001b[A\n",
            " 37% 195/528 [01:01<01:27,  3.80it/s]\u001b[A\n",
            " 37% 196/528 [01:01<01:30,  3.66it/s]\u001b[A\n",
            " 37% 197/528 [01:01<01:31,  3.60it/s]\u001b[A\n",
            " 38% 198/528 [01:02<01:30,  3.65it/s]\u001b[A\n",
            " 38% 199/528 [01:02<01:38,  3.34it/s]\u001b[A\n",
            " 38% 200/528 [01:02<01:45,  3.10it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.6527, 'grad_norm': 7.369242191314697, 'learning_rate': 1.5373831775700935e-05, 'epoch': 1.52}\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.6597043871879578, 'eval_f1_macro': 0.44144152171214784, 'eval_f1_micro': 0.7433712121212122, 'eval_f1_weighted': 0.687026189361499, 'eval_runtime': 1.9986, 'eval_samples_per_second': 528.361, 'eval_steps_per_second': 16.511, 'epoch': 1.52}\n",
            "100% 33/33 [00:01<00:00, 17.29it/s]\n",
            "\n",
            " 38% 201/528 [01:13<17:57,  3.30s/it]\u001b[A\n",
            " 38% 202/528 [01:13<13:14,  2.44s/it]\u001b[A\n",
            " 38% 203/528 [01:13<09:36,  1.77s/it]\u001b[A\n",
            " 39% 204/528 [01:13<07:01,  1.30s/it]\u001b[A\n",
            " 39% 205/528 [01:14<05:14,  1.03it/s]\u001b[A\n",
            " 39% 206/528 [01:14<03:59,  1.35it/s]\u001b[A\n",
            " 39% 207/528 [01:14<03:07,  1.71it/s]\u001b[A\n",
            " 39% 208/528 [01:14<02:30,  2.13it/s]\u001b[A\n",
            " 40% 209/528 [01:14<02:04,  2.56it/s]\u001b[A\n",
            " 40% 210/528 [01:15<01:46,  2.98it/s]\u001b[A\n",
            " 40% 211/528 [01:15<01:34,  3.35it/s]\u001b[A\n",
            " 40% 212/528 [01:15<01:26,  3.67it/s]\u001b[A\n",
            " 40% 213/528 [01:15<01:20,  3.94it/s]\u001b[A\n",
            " 41% 214/528 [01:15<01:15,  4.17it/s]\u001b[A\n",
            " 41% 215/528 [01:16<01:11,  4.37it/s]\u001b[A\n",
            " 41% 216/528 [01:16<01:09,  4.51it/s]\u001b[A\n",
            " 41% 217/528 [01:16<01:07,  4.63it/s]\u001b[A\n",
            " 41% 218/528 [01:16<01:05,  4.72it/s]\u001b[A\n",
            " 41% 219/528 [01:17<01:04,  4.76it/s]\u001b[A\n",
            " 42% 220/528 [01:17<01:04,  4.80it/s]\u001b[A\n",
            " 42% 221/528 [01:17<01:03,  4.83it/s]\u001b[A\n",
            " 42% 222/528 [01:17<01:03,  4.84it/s]\u001b[A\n",
            " 42% 223/528 [01:17<01:02,  4.85it/s]\u001b[A\n",
            " 42% 224/528 [01:18<01:02,  4.86it/s]\u001b[A\n",
            " 43% 225/528 [01:18<01:02,  4.87it/s]\u001b[A\n",
            " 43% 226/528 [01:18<01:01,  4.90it/s]\u001b[A\n",
            " 43% 227/528 [01:18<01:01,  4.91it/s]\u001b[A\n",
            " 43% 228/528 [01:18<01:00,  4.92it/s]\u001b[A\n",
            " 43% 229/528 [01:19<01:00,  4.91it/s]\u001b[A\n",
            " 44% 230/528 [01:19<01:00,  4.90it/s]\u001b[A\n",
            " 44% 231/528 [01:19<01:00,  4.90it/s]\u001b[A\n",
            " 44% 232/528 [01:19<01:00,  4.92it/s]\u001b[A\n",
            " 44% 233/528 [01:19<00:59,  4.92it/s]\u001b[A\n",
            " 44% 234/528 [01:20<00:59,  4.92it/s]\u001b[A\n",
            " 45% 235/528 [01:20<00:59,  4.90it/s]\u001b[A\n",
            " 45% 236/528 [01:20<01:00,  4.86it/s]\u001b[A\n",
            " 45% 237/528 [01:20<00:59,  4.87it/s]\u001b[A\n",
            " 45% 238/528 [01:20<00:59,  4.86it/s]\u001b[A\n",
            " 45% 239/528 [01:21<00:59,  4.87it/s]\u001b[A\n",
            " 45% 240/528 [01:21<00:59,  4.88it/s]\u001b[A\n",
            " 46% 241/528 [01:21<00:59,  4.86it/s]\u001b[A\n",
            " 46% 242/528 [01:21<00:58,  4.88it/s]\u001b[A\n",
            " 46% 243/528 [01:21<00:58,  4.91it/s]\u001b[A\n",
            " 46% 244/528 [01:22<00:58,  4.90it/s]\u001b[A\n",
            " 46% 245/528 [01:22<00:57,  4.89it/s]\u001b[A\n",
            " 47% 246/528 [01:22<00:58,  4.86it/s]\u001b[A\n",
            " 47% 247/528 [01:22<00:57,  4.90it/s]\u001b[A\n",
            " 47% 248/528 [01:22<00:57,  4.86it/s]\u001b[A\n",
            " 47% 249/528 [01:23<00:57,  4.87it/s]\u001b[A\n",
            " 47% 250/528 [01:23<00:56,  4.88it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.6639, 'grad_norm': 6.141462802886963, 'learning_rate': 1.3037383177570095e-05, 'epoch': 1.89}\n",
            "\n",
            " 47% 250/528 [01:23<00:56,  4.88it/s]\u001b[A\n",
            " 48% 251/528 [01:23<00:56,  4.87it/s]\u001b[A\n",
            " 48% 252/528 [01:23<00:56,  4.90it/s]\u001b[A\n",
            " 48% 253/528 [01:23<00:56,  4.89it/s]\u001b[A\n",
            " 48% 254/528 [01:24<00:56,  4.87it/s]\u001b[A\n",
            " 48% 255/528 [01:24<00:55,  4.88it/s]\u001b[A\n",
            " 48% 256/528 [01:24<00:56,  4.85it/s]\u001b[A\n",
            " 49% 257/528 [01:24<00:55,  4.88it/s]\u001b[A\n",
            " 49% 258/528 [01:25<00:55,  4.87it/s]\u001b[A\n",
            " 49% 259/528 [01:25<00:55,  4.87it/s]\u001b[A\n",
            " 49% 260/528 [01:25<00:54,  4.88it/s]\u001b[A\n",
            " 49% 261/528 [01:25<00:55,  4.84it/s]\u001b[A\n",
            " 50% 262/528 [01:25<00:54,  4.85it/s]\u001b[A\n",
            " 50% 263/528 [01:26<00:54,  4.86it/s]\u001b[A\n",
            " 50% 264/528 [01:26<00:54,  4.88it/s]\u001b[A\n",
            " 50% 265/528 [01:26<00:54,  4.80it/s]\u001b[A\n",
            " 50% 266/528 [01:26<00:55,  4.75it/s]\u001b[A\n",
            " 51% 267/528 [01:26<00:55,  4.72it/s]\u001b[A\n",
            " 51% 268/528 [01:27<00:55,  4.72it/s]\u001b[A\n",
            " 51% 269/528 [01:27<00:54,  4.72it/s]\u001b[A\n",
            " 51% 270/528 [01:27<00:54,  4.72it/s]\u001b[A\n",
            " 51% 271/528 [01:27<00:54,  4.69it/s]\u001b[A\n",
            " 52% 272/528 [01:27<00:56,  4.55it/s]\u001b[A\n",
            " 52% 273/528 [01:28<00:55,  4.61it/s]\u001b[A\n",
            " 52% 274/528 [01:28<00:53,  4.72it/s]\u001b[A\n",
            " 52% 275/528 [01:28<00:53,  4.74it/s]\u001b[A\n",
            " 52% 276/528 [01:28<00:53,  4.75it/s]\u001b[A\n",
            " 52% 277/528 [01:29<00:52,  4.79it/s]\u001b[A\n",
            " 53% 278/528 [01:29<00:52,  4.80it/s]\u001b[A\n",
            " 53% 279/528 [01:29<00:51,  4.82it/s]\u001b[A\n",
            " 53% 280/528 [01:29<00:51,  4.82it/s]\u001b[A\n",
            " 53% 281/528 [01:29<00:51,  4.79it/s]\u001b[A\n",
            " 53% 282/528 [01:30<00:51,  4.80it/s]\u001b[A\n",
            " 54% 283/528 [01:30<00:50,  4.81it/s]\u001b[A\n",
            " 54% 284/528 [01:30<00:50,  4.79it/s]\u001b[A\n",
            " 54% 285/528 [01:30<00:50,  4.80it/s]\u001b[A\n",
            " 54% 286/528 [01:30<00:50,  4.78it/s]\u001b[A\n",
            " 54% 287/528 [01:31<00:50,  4.81it/s]\u001b[A\n",
            " 55% 288/528 [01:31<00:50,  4.80it/s]\u001b[A\n",
            " 55% 289/528 [01:31<00:49,  4.81it/s]\u001b[A\n",
            " 55% 290/528 [01:31<00:49,  4.81it/s]\u001b[A\n",
            " 55% 291/528 [01:31<00:49,  4.80it/s]\u001b[A\n",
            " 55% 292/528 [01:32<00:49,  4.81it/s]\u001b[A\n",
            " 55% 293/528 [01:32<00:48,  4.83it/s]\u001b[A\n",
            " 56% 294/528 [01:32<00:48,  4.80it/s]\u001b[A\n",
            " 56% 295/528 [01:32<00:48,  4.81it/s]\u001b[A\n",
            " 56% 296/528 [01:32<00:48,  4.76it/s]\u001b[A\n",
            " 56% 297/528 [01:33<00:48,  4.78it/s]\u001b[A\n",
            " 56% 298/528 [01:33<00:48,  4.78it/s]\u001b[A\n",
            " 57% 299/528 [01:33<00:47,  4.77it/s]\u001b[A\n",
            " 57% 300/528 [01:33<00:47,  4.79it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.6189, 'grad_norm': 8.848002433776855, 'learning_rate': 1.0700934579439253e-05, 'epoch': 2.27}\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.6612364053726196, 'eval_f1_macro': 0.5761265676742265, 'eval_f1_micro': 0.7339015151515151, 'eval_f1_weighted': 0.7275673695920134, 'eval_runtime': 1.6553, 'eval_samples_per_second': 637.949, 'eval_steps_per_second': 19.936, 'epoch': 2.27}\n",
            "100% 33/33 [00:01<00:00, 20.07it/s]\n",
            "\n",
            " 57% 301/528 [02:02<33:00,  8.73s/it]\u001b[A\n",
            " 57% 302/528 [02:02<23:14,  6.17s/it]\u001b[A\n",
            " 57% 303/528 [02:02<16:27,  4.39s/it]\u001b[A\n",
            " 58% 304/528 [02:03<11:42,  3.14s/it]\u001b[A\n",
            " 58% 305/528 [02:03<08:24,  2.26s/it]\u001b[A\n",
            " 58% 306/528 [02:03<06:05,  1.65s/it]\u001b[A\n",
            " 58% 307/528 [02:03<04:28,  1.21s/it]\u001b[A\n",
            " 58% 308/528 [02:03<03:20,  1.10it/s]\u001b[A\n",
            " 59% 309/528 [02:04<02:33,  1.43it/s]\u001b[A\n",
            " 59% 310/528 [02:04<02:00,  1.81it/s]\u001b[A\n",
            " 59% 311/528 [02:04<01:37,  2.23it/s]\u001b[A\n",
            " 59% 312/528 [02:04<01:21,  2.66it/s]\u001b[A\n",
            " 59% 313/528 [02:04<01:10,  3.06it/s]\u001b[A\n",
            " 59% 314/528 [02:05<01:02,  3.44it/s]\u001b[A\n",
            " 60% 315/528 [02:05<00:56,  3.76it/s]\u001b[A\n",
            " 60% 316/528 [02:05<00:52,  4.03it/s]\u001b[A\n",
            " 60% 317/528 [02:05<00:49,  4.25it/s]\u001b[A\n",
            " 60% 318/528 [02:05<00:47,  4.39it/s]\u001b[A\n",
            " 60% 319/528 [02:06<00:46,  4.50it/s]\u001b[A\n",
            " 61% 320/528 [02:06<00:45,  4.58it/s]\u001b[A\n",
            " 61% 321/528 [02:06<00:44,  4.64it/s]\u001b[A\n",
            " 61% 322/528 [02:06<00:43,  4.70it/s]\u001b[A\n",
            " 61% 323/528 [02:07<00:43,  4.71it/s]\u001b[A\n",
            " 61% 324/528 [02:07<00:43,  4.73it/s]\u001b[A\n",
            " 62% 325/528 [02:07<00:42,  4.76it/s]\u001b[A\n",
            " 62% 326/528 [02:07<00:42,  4.79it/s]\u001b[A\n",
            " 62% 327/528 [02:07<00:42,  4.76it/s]\u001b[A\n",
            " 62% 328/528 [02:08<00:42,  4.76it/s]\u001b[A\n",
            " 62% 329/528 [02:08<00:41,  4.78it/s]\u001b[A\n",
            " 62% 330/528 [02:08<00:41,  4.77it/s]\u001b[A\n",
            " 63% 331/528 [02:08<00:41,  4.77it/s]\u001b[A\n",
            " 63% 332/528 [02:08<00:40,  4.78it/s]\u001b[A\n",
            " 63% 333/528 [02:09<00:40,  4.77it/s]\u001b[A\n",
            " 63% 334/528 [02:09<00:40,  4.77it/s]\u001b[A\n",
            " 63% 335/528 [02:09<00:40,  4.78it/s]\u001b[A\n",
            " 64% 336/528 [02:09<00:40,  4.77it/s]\u001b[A\n",
            " 64% 337/528 [02:09<00:40,  4.76it/s]\u001b[A\n",
            " 64% 338/528 [02:10<00:39,  4.77it/s]\u001b[A\n",
            " 64% 339/528 [02:10<00:39,  4.77it/s]\u001b[A\n",
            " 64% 340/528 [02:10<00:39,  4.76it/s]\u001b[A\n",
            " 65% 341/528 [02:10<00:39,  4.77it/s]\u001b[A\n",
            " 65% 342/528 [02:10<00:38,  4.78it/s]\u001b[A\n",
            " 65% 343/528 [02:11<00:38,  4.78it/s]\u001b[A\n",
            " 65% 344/528 [02:11<00:38,  4.78it/s]\u001b[A\n",
            " 65% 345/528 [02:11<00:38,  4.79it/s]\u001b[A\n",
            " 66% 346/528 [02:11<00:37,  4.79it/s]\u001b[A\n",
            " 66% 347/528 [02:12<00:37,  4.78it/s]\u001b[A\n",
            " 66% 348/528 [02:12<00:37,  4.79it/s]\u001b[A\n",
            " 66% 349/528 [02:12<00:37,  4.79it/s]\u001b[A\n",
            " 66% 350/528 [02:12<00:37,  4.80it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.5695, 'grad_norm': 19.751346588134766, 'learning_rate': 8.364485981308411e-06, 'epoch': 2.65}\n",
            "\n",
            " 66% 350/528 [02:12<00:37,  4.80it/s]\u001b[A\n",
            " 66% 351/528 [02:12<00:37,  4.77it/s]\u001b[A\n",
            " 67% 352/528 [02:13<00:36,  4.78it/s]\u001b[A\n",
            " 67% 353/528 [02:13<00:36,  4.78it/s]\u001b[A\n",
            " 67% 354/528 [02:13<00:36,  4.75it/s]\u001b[A\n",
            " 67% 355/528 [02:13<00:36,  4.71it/s]\u001b[A\n",
            " 67% 356/528 [02:13<00:36,  4.69it/s]\u001b[A\n",
            " 68% 357/528 [02:14<00:36,  4.69it/s]\u001b[A\n",
            " 68% 358/528 [02:14<00:36,  4.69it/s]\u001b[A\n",
            " 68% 359/528 [02:14<00:36,  4.66it/s]\u001b[A\n",
            " 68% 360/528 [02:14<00:35,  4.68it/s]\u001b[A\n",
            " 68% 361/528 [02:15<00:35,  4.65it/s]\u001b[A\n",
            " 69% 362/528 [02:15<00:35,  4.62it/s]\u001b[A\n",
            " 69% 363/528 [02:15<00:35,  4.62it/s]\u001b[A\n",
            " 69% 364/528 [02:15<00:35,  4.63it/s]\u001b[A\n",
            " 69% 365/528 [02:15<00:34,  4.66it/s]\u001b[A\n",
            " 69% 366/528 [02:16<00:34,  4.68it/s]\u001b[A\n",
            " 70% 367/528 [02:16<00:34,  4.66it/s]\u001b[A\n",
            " 70% 368/528 [02:16<00:34,  4.68it/s]\u001b[A\n",
            " 70% 369/528 [02:16<00:33,  4.72it/s]\u001b[A\n",
            " 70% 370/528 [02:16<00:33,  4.72it/s]\u001b[A\n",
            " 70% 371/528 [02:17<00:33,  4.75it/s]\u001b[A\n",
            " 70% 372/528 [02:17<00:32,  4.73it/s]\u001b[A\n",
            " 71% 373/528 [02:17<00:32,  4.72it/s]\u001b[A\n",
            " 71% 374/528 [02:17<00:32,  4.74it/s]\u001b[A\n",
            " 71% 375/528 [02:17<00:32,  4.74it/s]\u001b[A\n",
            " 71% 376/528 [02:18<00:31,  4.76it/s]\u001b[A\n",
            " 71% 377/528 [02:18<00:31,  4.72it/s]\u001b[A\n",
            " 72% 378/528 [02:18<00:31,  4.75it/s]\u001b[A\n",
            " 72% 379/528 [02:18<00:31,  4.75it/s]\u001b[A\n",
            " 72% 380/528 [02:19<00:31,  4.75it/s]\u001b[A\n",
            " 72% 381/528 [02:19<00:30,  4.78it/s]\u001b[A\n",
            " 72% 382/528 [02:19<00:30,  4.74it/s]\u001b[A\n",
            " 73% 383/528 [02:19<00:30,  4.76it/s]\u001b[A\n",
            " 73% 384/528 [02:19<00:30,  4.76it/s]\u001b[A\n",
            " 73% 385/528 [02:20<00:30,  4.74it/s]\u001b[A\n",
            " 73% 386/528 [02:20<00:29,  4.75it/s]\u001b[A\n",
            " 73% 387/528 [02:20<00:29,  4.73it/s]\u001b[A\n",
            " 73% 388/528 [02:20<00:29,  4.74it/s]\u001b[A\n",
            " 74% 389/528 [02:20<00:29,  4.74it/s]\u001b[A\n",
            " 74% 390/528 [02:21<00:29,  4.73it/s]\u001b[A\n",
            " 74% 391/528 [02:21<00:29,  4.72it/s]\u001b[A\n",
            " 74% 392/528 [02:21<00:28,  4.70it/s]\u001b[A\n",
            " 74% 393/528 [02:21<00:28,  4.72it/s]\u001b[A\n",
            " 75% 394/528 [02:21<00:28,  4.72it/s]\u001b[A\n",
            " 75% 395/528 [02:22<00:28,  4.71it/s]\u001b[A\n",
            " 75% 396/528 [02:22<00:27,  4.75it/s]\u001b[A\n",
            " 75% 397/528 [02:22<00:27,  4.74it/s]\u001b[A\n",
            " 75% 398/528 [02:22<00:27,  4.73it/s]\u001b[A\n",
            " 76% 399/528 [02:23<00:27,  4.73it/s]\u001b[A\n",
            " 76% 400/528 [02:23<00:27,  4.72it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.5375, 'grad_norm': 7.633486747741699, 'learning_rate': 6.028037383177571e-06, 'epoch': 3.03}\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.6674962043762207, 'eval_f1_macro': 0.5281294932532412, 'eval_f1_micro': 0.7310606060606061, 'eval_f1_weighted': 0.7102085716647749, 'eval_runtime': 1.7397, 'eval_samples_per_second': 606.998, 'eval_steps_per_second': 18.969, 'epoch': 3.03}\n",
            "100% 33/33 [00:01<00:00, 18.84it/s]\n",
            "\n",
            " 76% 401/528 [03:35<46:25, 21.94s/it]\u001b[A\n",
            " 76% 402/528 [03:36<32:22, 15.42s/it]\u001b[A\n",
            " 76% 403/528 [03:36<22:37, 10.86s/it]\u001b[A\n",
            " 77% 404/528 [03:36<15:50,  7.66s/it]\u001b[A\n",
            " 77% 405/528 [03:36<11:07,  5.43s/it]\u001b[A\n",
            " 77% 406/528 [03:36<07:51,  3.86s/it]\u001b[A\n",
            " 77% 407/528 [03:37<05:34,  2.77s/it]\u001b[A\n",
            " 77% 408/528 [03:37<04:00,  2.00s/it]\u001b[A\n",
            " 77% 409/528 [03:37<02:54,  1.46s/it]\u001b[A\n",
            " 78% 410/528 [03:37<02:08,  1.09s/it]\u001b[A\n",
            " 78% 411/528 [03:37<01:36,  1.21it/s]\u001b[A\n",
            " 78% 412/528 [03:38<01:14,  1.56it/s]\u001b[A\n",
            " 78% 413/528 [03:38<00:58,  1.96it/s]\u001b[A\n",
            " 78% 414/528 [03:38<00:48,  2.36it/s]\u001b[A\n",
            " 79% 415/528 [03:38<00:40,  2.77it/s]\u001b[A\n",
            " 79% 416/528 [03:39<00:35,  3.16it/s]\u001b[A\n",
            " 79% 417/528 [03:39<00:31,  3.49it/s]\u001b[A\n",
            " 79% 418/528 [03:39<00:29,  3.77it/s]\u001b[A\n",
            " 79% 419/528 [03:39<00:27,  4.00it/s]\u001b[A\n",
            " 80% 420/528 [03:39<00:25,  4.17it/s]\u001b[A\n",
            " 80% 421/528 [03:40<00:24,  4.30it/s]\u001b[A\n",
            " 80% 422/528 [03:40<00:24,  4.39it/s]\u001b[A\n",
            " 80% 423/528 [03:40<00:23,  4.46it/s]\u001b[A\n",
            " 80% 424/528 [03:40<00:22,  4.54it/s]\u001b[A\n",
            " 80% 425/528 [03:40<00:22,  4.60it/s]\u001b[A\n",
            " 81% 426/528 [03:41<00:21,  4.64it/s]\u001b[A\n",
            " 81% 427/528 [03:41<00:21,  4.65it/s]\u001b[A\n",
            " 81% 428/528 [03:41<00:21,  4.66it/s]\u001b[A\n",
            " 81% 429/528 [03:41<00:21,  4.68it/s]\u001b[A\n",
            " 81% 430/528 [03:42<00:20,  4.70it/s]\u001b[A\n",
            " 82% 431/528 [03:42<00:20,  4.69it/s]\u001b[A\n",
            " 82% 432/528 [03:42<00:20,  4.71it/s]\u001b[A\n",
            " 82% 433/528 [03:42<00:20,  4.72it/s]\u001b[A\n",
            " 82% 434/528 [03:42<00:19,  4.72it/s]\u001b[A\n",
            " 82% 435/528 [03:43<00:19,  4.72it/s]\u001b[A\n",
            " 83% 436/528 [03:43<00:19,  4.73it/s]\u001b[A\n",
            " 83% 437/528 [03:43<00:19,  4.73it/s]\u001b[A\n",
            " 83% 438/528 [03:43<00:19,  4.73it/s]\u001b[A\n",
            " 83% 439/528 [03:43<00:18,  4.73it/s]\u001b[A\n",
            " 83% 440/528 [03:44<00:18,  4.73it/s]\u001b[A\n",
            " 84% 441/528 [03:44<00:18,  4.74it/s]\u001b[A\n",
            " 84% 442/528 [03:44<00:18,  4.73it/s]\u001b[A\n",
            " 84% 443/528 [03:44<00:18,  4.70it/s]\u001b[A\n",
            " 84% 444/528 [03:45<00:17,  4.72it/s]\u001b[A\n",
            " 84% 445/528 [03:45<00:17,  4.72it/s]\u001b[A\n",
            " 84% 446/528 [03:45<00:17,  4.71it/s]\u001b[A\n",
            " 85% 447/528 [03:45<00:17,  4.68it/s]\u001b[A\n",
            " 85% 448/528 [03:45<00:17,  4.69it/s]\u001b[A\n",
            " 85% 449/528 [03:46<00:16,  4.70it/s]\u001b[A\n",
            " 85% 450/528 [03:46<00:16,  4.72it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.4828, 'grad_norm': 9.676993370056152, 'learning_rate': 3.691588785046729e-06, 'epoch': 3.41}\n",
            "\n",
            " 85% 450/528 [03:46<00:16,  4.72it/s]\u001b[A\n",
            " 85% 451/528 [03:46<00:16,  4.72it/s]\u001b[A\n",
            " 86% 452/528 [03:46<00:16,  4.72it/s]\u001b[A\n",
            " 86% 453/528 [03:46<00:15,  4.71it/s]\u001b[A\n",
            " 86% 454/528 [03:47<00:15,  4.71it/s]\u001b[A\n",
            " 86% 455/528 [03:47<00:15,  4.70it/s]\u001b[A\n",
            " 86% 456/528 [03:47<00:15,  4.68it/s]\u001b[A\n",
            " 87% 457/528 [03:47<00:15,  4.69it/s]\u001b[A\n",
            " 87% 458/528 [03:47<00:14,  4.69it/s]\u001b[A\n",
            " 87% 459/528 [03:48<00:14,  4.68it/s]\u001b[A\n",
            " 87% 460/528 [03:48<00:14,  4.68it/s]\u001b[A\n",
            " 87% 461/528 [03:48<00:14,  4.69it/s]\u001b[A\n",
            " 88% 462/528 [03:48<00:14,  4.69it/s]\u001b[A\n",
            " 88% 463/528 [03:49<00:13,  4.68it/s]\u001b[A\n",
            " 88% 464/528 [03:49<00:13,  4.69it/s]\u001b[A\n",
            " 88% 465/528 [03:49<00:13,  4.70it/s]\u001b[A\n",
            " 88% 466/528 [03:49<00:13,  4.68it/s]\u001b[A\n",
            " 88% 467/528 [03:49<00:12,  4.69it/s]\u001b[A\n",
            " 89% 468/528 [03:50<00:12,  4.69it/s]\u001b[A\n",
            " 89% 469/528 [03:50<00:12,  4.70it/s]\u001b[A\n",
            " 89% 470/528 [03:50<00:12,  4.68it/s]\u001b[A\n",
            " 89% 471/528 [03:50<00:12,  4.67it/s]\u001b[A\n",
            " 89% 472/528 [03:50<00:12,  4.61it/s]\u001b[A\n",
            " 90% 473/528 [03:51<00:11,  4.63it/s]\u001b[A\n",
            " 90% 474/528 [03:51<00:11,  4.62it/s]\u001b[A\n",
            " 90% 475/528 [03:51<00:11,  4.63it/s]\u001b[A\n",
            " 90% 476/528 [03:51<00:11,  4.61it/s]\u001b[A\n",
            " 90% 477/528 [03:52<00:11,  4.57it/s]\u001b[A\n",
            " 91% 478/528 [03:52<00:10,  4.57it/s]\u001b[A\n",
            " 91% 479/528 [03:52<00:10,  4.57it/s]\u001b[A\n",
            " 91% 480/528 [03:52<00:10,  4.61it/s]\u001b[A\n",
            " 91% 481/528 [03:52<00:10,  4.60it/s]\u001b[A\n",
            " 91% 482/528 [03:53<00:09,  4.65it/s]\u001b[A\n",
            " 91% 483/528 [03:53<00:09,  4.66it/s]\u001b[A\n",
            " 92% 484/528 [03:53<00:09,  4.66it/s]\u001b[A\n",
            " 92% 485/528 [03:53<00:09,  4.65it/s]\u001b[A\n",
            " 92% 486/528 [03:54<00:08,  4.67it/s]\u001b[A\n",
            " 92% 487/528 [03:54<00:08,  4.67it/s]\u001b[A\n",
            " 92% 488/528 [03:54<00:08,  4.66it/s]\u001b[A\n",
            " 93% 489/528 [03:54<00:08,  4.66it/s]\u001b[A\n",
            " 93% 490/528 [03:54<00:08,  4.67it/s]\u001b[A\n",
            " 93% 491/528 [03:55<00:07,  4.65it/s]\u001b[A\n",
            " 93% 492/528 [03:55<00:07,  4.65it/s]\u001b[A\n",
            " 93% 493/528 [03:55<00:07,  4.66it/s]\u001b[A\n",
            " 94% 494/528 [03:55<00:07,  4.66it/s]\u001b[A\n",
            " 94% 495/528 [03:55<00:07,  4.66it/s]\u001b[A\n",
            " 94% 496/528 [03:56<00:06,  4.66it/s]\u001b[A\n",
            " 94% 497/528 [03:56<00:06,  4.66it/s]\u001b[A\n",
            " 94% 498/528 [03:56<00:06,  4.68it/s]\u001b[A\n",
            " 95% 499/528 [03:56<00:06,  4.66it/s]\u001b[A\n",
            " 95% 500/528 [03:57<00:05,  4.67it/s]\u001b[A\n",
            "\u001b[A{'loss': 0.4621, 'grad_norm': 6.8435797691345215, 'learning_rate': 1.3551401869158879e-06, 'epoch': 3.79}\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.7214174270629883, 'eval_f1_macro': 0.5683674521153322, 'eval_f1_micro': 0.7083333333333334, 'eval_f1_weighted': 0.7115222634990158, 'eval_runtime': 1.7746, 'eval_samples_per_second': 595.059, 'eval_steps_per_second': 18.596, 'epoch': 3.79}\n",
            "100% 33/33 [00:01<00:00, 18.62it/s]\n",
            "\n",
            " 95% 501/528 [04:47<06:54, 15.36s/it]\u001b[A\n",
            " 95% 502/528 [04:47<04:41, 10.82s/it]\u001b[A\n",
            " 95% 503/528 [04:48<03:10,  7.63s/it]\u001b[A\n",
            " 95% 504/528 [04:48<02:10,  5.42s/it]\u001b[A\n",
            " 96% 505/528 [04:48<01:28,  3.86s/it]\u001b[A\n",
            " 96% 506/528 [04:48<01:00,  2.76s/it]\u001b[A\n",
            " 96% 507/528 [04:49<00:41,  2.00s/it]\u001b[A\n",
            " 96% 508/528 [04:49<00:29,  1.46s/it]\u001b[A\n",
            " 96% 509/528 [04:49<00:20,  1.09s/it]\u001b[A\n",
            " 97% 510/528 [04:49<00:14,  1.21it/s]\u001b[A\n",
            " 97% 511/528 [04:49<00:10,  1.56it/s]\u001b[A\n",
            " 97% 512/528 [04:50<00:08,  1.95it/s]\u001b[A\n",
            " 97% 513/528 [04:50<00:06,  2.36it/s]\u001b[A\n",
            " 97% 514/528 [04:50<00:05,  2.80it/s]\u001b[A\n",
            " 98% 515/528 [04:50<00:04,  3.20it/s]\u001b[A\n",
            " 98% 516/528 [04:50<00:03,  3.55it/s]\u001b[A\n",
            " 98% 517/528 [04:51<00:02,  3.84it/s]\u001b[A\n",
            " 98% 518/528 [04:51<00:02,  4.11it/s]\u001b[A\n",
            " 98% 519/528 [04:51<00:02,  4.30it/s]\u001b[A\n",
            " 98% 520/528 [04:51<00:01,  4.45it/s]\u001b[A\n",
            " 99% 521/528 [04:51<00:01,  4.55it/s]\u001b[A\n",
            " 99% 522/528 [04:52<00:01,  4.63it/s]\u001b[A\n",
            " 99% 523/528 [04:52<00:01,  4.68it/s]\u001b[A\n",
            " 99% 524/528 [04:52<00:00,  4.69it/s]\u001b[A\n",
            " 99% 525/528 [04:52<00:00,  4.73it/s]\u001b[A\n",
            "100% 526/528 [04:53<00:00,  4.75it/s]\u001b[A\n",
            "100% 527/528 [04:53<00:00,  4.76it/s]\u001b[A\n",
            "100% 528/528 [04:53<00:00,  4.81it/s]\u001b[A\n",
            "\u001b[A{'train_runtime': 331.3392, 'train_samples_per_second': 50.981, 'train_steps_per_second': 1.594, 'train_loss': 0.6493754567521991, 'epoch': 4.0}\n",
            "\n",
            "100% 528/528 [05:31<00:00,  1.59it/s]\n",
            "\n",
            "📊 Evaluating model...\n",
            "100% 33/33 [00:01<00:00, 20.17it/s]\n",
            "\n",
            "=== Transformer (RoBERTa) Results ===\n",
            "📊 Macro F1: 0.5761\n",
            "📊 Micro F1: 0.7339\n",
            "📊 Weighted F1: 0.7276\n",
            "🎯 Target: 0.470 | Status: ✅ PASS\n",
            "\n",
            "🔍 Generating predictions for analysis...\n",
            "100% 33/33 [00:01<00:00, 20.53it/s]\n",
            "\n",
            "============================================================\n",
            "DETAILED PREDICTION ANALYSIS\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.44      0.36      0.40       123\n",
            "    negative       0.52      0.49      0.50       168\n",
            "     neutral       0.81      0.85      0.83       765\n",
            "\n",
            "    accuracy                           0.73      1056\n",
            "   macro avg       0.59      0.56      0.58      1056\n",
            "weighted avg       0.72      0.73      0.73      1056\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "True\\Pred positive\tnegative\tneutral\n",
            "positive\t44\t9\t70\n",
            "negative\t7\t82\t79\n",
            "neutral \t48\t68\t649\n",
            "\n",
            "📊 Creating transformer performance visualization...\n",
            "   Saved as: transformer_performance.png\n",
            "\n",
            "💾 Saving model...\n",
            "\n",
            "============================================================\n",
            "TRANSFORMER TRAINING SUMMARY\n",
            "============================================================\n",
            "Model: RoBERTa | Macro F1: 0.5761 | ✅ PASS\n",
            "🎯 Target F1-score: 0.47\n",
            "🏆 Achieved: 0.5761\n",
            "🎉 SUCCESS! Model meets target performance.\n",
            "\n",
            "📁 Files created:\n",
            "   • ./transformer_model/ (fine-tuned model + tokenizer)\n",
            "   • transformer_model_info.pkl (metadata for inference)\n",
            "   • transformer_performance.png (performance chart)\n",
            "   • MLflow logs in ./mlruns/\n",
            "\n",
            "▶️  Next step: Use model.py --predict or --test for inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing single prediction"
      ],
      "metadata": {
        "id": "NnvhcnU-8uaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/model.py --predict \"This drug works great\" --drug \"Aspirin\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzH7xpgY7Gfo",
        "outputId": "92da0435-68da-4519-eff5-34410ec9e2e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:24:31.897116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707871.917316   12750 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707871.923586   12750 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707871.939229   12750 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707871.939257   12750 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707871.939263   12750 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707871.939267   12750 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:24:31.944007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Loaded transformer model: ./transformer_model (F1: 0.5761265676742265)\n",
            "Input: This drug works great\n",
            "Drug: Aspirin\n",
            "Predicted Sentiment: positive\n",
            "Probabilities: [0.72349495 0.05247525 0.22402972]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/model.py --predict \"This medication caused severe side effects\" --drug \"DrugX\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bzdTiZI8x4t",
        "outputId": "202ff1ed-515a-4559-ea17-4d722e4bed42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:25:04.217081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756707904.238000   12905 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756707904.244129   12905 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756707904.259450   12905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707904.259474   12905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707904.259479   12905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756707904.259484   12905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:25:04.265173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Loaded transformer model: ./transformer_model (F1: 0.5761265676742265)\n",
            "Input: This medication caused severe side effects\n",
            "Drug: DrugX\n",
            "Predicted Sentiment: negative\n",
            "Probabilities: [0.35697129 0.59347975 0.04954892]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/model.py --test data/test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciWMZ5GZ85Xn",
        "outputId": "6deb4511-f220-419c-a990-9db607f499dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-01 06:46:05.723933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756709165.757465   18168 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756709165.767424   18168 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756709165.791750   18168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756709165.791786   18168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756709165.791794   18168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756709165.791801   18168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-01 06:46:05.798621: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Loaded transformer model: ./transformer_model (F1: 0.5761265676742265)\n",
            "Predicting:   0% 8/2924 [00:00<01:14, 39.33it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Predicting: 100% 2924/2924 [00:28<00:00, 103.18it/s]\n",
            "Saved predictions to submission.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}